{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembly\n",
    "\n",
    "> assembly related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from __future__ import annotations\n",
    "from chem_templates.imports import *\n",
    "from chem_templates.utils import *\n",
    "from chem_templates.chem import Molecule, to_smile\n",
    "from chem_templates.filter import Template, TemplateResult\n",
    "from chem_templates.fragments import combine_dummies, get_dummy_mol, generate_mapping_permutations,\\\n",
    "match_mapping, fuse_smile_on_atom_mapping\n",
    "from chem_templates.building_blocks import Synthon, ReactionUniverse, REACTION_GROUPS, molecule_to_synthon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AssemblyPool():\n",
    "    def __init__(self, items: list[Molecule]):\n",
    "        self.items = items\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Molecule:\n",
    "        return self.items[idx]\n",
    "    \n",
    "    def filter(self, filter_func: Callable, worker_pool: Optional[Pool]=None) -> AssemblyPool:\n",
    "        if worker_pool:\n",
    "            bools = worker_pool.map(filter_func, self.items)\n",
    "            \n",
    "        else:\n",
    "            bools = [filter_func(i) for i in self.items]\n",
    "            \n",
    "        return AssemblyPool([self.items[i] for i in range(len(self.items)) if bools[i]])\n",
    "    \n",
    "    def deduplicate(self, key_func: Callable) -> AssemblyPool:\n",
    "        item_dict = {}\n",
    "        for item in self.items:\n",
    "            item_dict[key_func(item)] = item\n",
    "        \n",
    "        return AssemblyPool(list(item_dict.values()))\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'AssemblyPool: {len(self.items)} items'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = AssemblyPool([Molecule('C'), Molecule('CCCCC')])\n",
    "assert len(pool)==2\n",
    "def filter_func(molecule):\n",
    "    return len(molecule.smile)>1\n",
    "\n",
    "pool2 = pool.filter(filter_func)\n",
    "assert len(pool2)==1\n",
    "\n",
    "pool = AssemblyPool([Molecule('C'), Molecule('C'), Molecule('C')])\n",
    "pool = pool.deduplicate(lambda x: x.smile)\n",
    "assert len(pool)==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AssemblyInputs():\n",
    "    def __init__(self, \n",
    "                 pool_dict: dict[str, AssemblyPool], \n",
    "                 assembly_chunksize: int,\n",
    "                 max_assemblies_per_node: int,\n",
    "                 worker_pool: Optional[Pool]=None, \n",
    "                 log: bool=True):\n",
    "        \n",
    "        self.pool_dict = pool_dict\n",
    "        self.assembly_chunksize = assembly_chunksize\n",
    "        self.max_assemblies_per_node = max_assemblies_per_node\n",
    "        \n",
    "        self.worker_pool = worker_pool\n",
    "            \n",
    "        self.log = log\n",
    "        self.assembly_log = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, \n",
    "                 name: str, \n",
    "                 template: Optional[Template]=None):\n",
    "        self.name = name\n",
    "        self.template = template\n",
    "        \n",
    "    def template_screen(self, molecule: Molecule, add_template_data=False) -> bool:\n",
    "        if self.template is not None:\n",
    "            output = self.template(molecule)\n",
    "        else:\n",
    "            output = TemplateResult(True, [], [])\n",
    "        \n",
    "        if add_template_data:\n",
    "            molecule.add_data({'template_data' : output, 'template_result' : output.result})\n",
    "            \n",
    "        return output.result\n",
    "    \n",
    "    def _fuse(self, fusion_input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def fuse(self, fusion_inputs, worker_pool: Optional[Pool]=None):\n",
    "        if worker_pool:\n",
    "            outputs = worker_pool.map(self._fuse, fusion_inputs)\n",
    "        else:\n",
    "            outputs = [self._fuse(i) for i in fusion_inputs]\n",
    "        return AssemblyPool(outputs)\n",
    "    \n",
    "    def dump(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class FragmentNode(Node):\n",
    "    def __init__(self, \n",
    "                 name: str, \n",
    "                 children: list[FragmentNode], \n",
    "                 template: Optional[Template]=None):\n",
    "        super().__init__(name, template)\n",
    "        self.children = children\n",
    "        self.build_ids()\n",
    "        self.build_dummies()\n",
    "        self.grab_leaf_nodes()\n",
    "        \n",
    "    def build_ids(self):\n",
    "        stack = [self]\n",
    "        current_id = 1\n",
    "        while stack:\n",
    "            current = stack.pop()\n",
    "            current.id = current_id\n",
    "            current_id += 1\n",
    "            \n",
    "            for child in getattr(current, 'children', []):\n",
    "                stack.append(child)\n",
    "                \n",
    "    def build_dummy(self):\n",
    "        self.dummy = combine_dummies([child.dummy for child in self.children])\n",
    "        self.dummy_smile = to_smile(self.dummy)\n",
    "        patt = re.compile('\\[\\*(.*?)]')\n",
    "        self.mapping_idxs = sorted([int(i[1:]) for i in patt.findall(self.dummy_smile)])\n",
    "                \n",
    "    def build_dummies(self):\n",
    "        for child in self.children:\n",
    "            child.build_dummies()\n",
    "            \n",
    "        self.build_dummy()\n",
    "        \n",
    "    def grab_leaf_nodes(self):\n",
    "        self.leaf_nodes = []\n",
    "        stack = [self]\n",
    "        while stack:\n",
    "            current = stack.pop()\n",
    "            if current.children:\n",
    "                stack += current.children\n",
    "            else:\n",
    "                self.leaf_nodes.append(current)\n",
    "                \n",
    "    def map_molecule_to_leaf_nodes(self, molecule: Molecule) -> dict[str, list[Molecule]]:\n",
    "        output = {}\n",
    "        for node in self.leaf_nodes:\n",
    "            output[node.name] = node.map_and_screen(molecule)\n",
    "        return output\n",
    "    \n",
    "    def build_assembly_pools(self, \n",
    "                             molecules: list[Molecule], \n",
    "                             worker_pool: Optional[Pool]=None\n",
    "                            ) -> dict[str, AssemblyPool]:\n",
    "        if worker_pool:\n",
    "            mappings = worker_pool.map(self.map_molecule_to_leaf_nodes, molecules)\n",
    "        else:\n",
    "            mappings = [self.map_molecule_to_leaf_nodes(i) for i in molecules]\n",
    "            \n",
    "        pool_inputs = defaultdict(list)\n",
    "        for mapping in mappings:\n",
    "            for k,v in mapping.items():\n",
    "                pool_inputs[k] += v\n",
    "                \n",
    "        return {k:AssemblyPool(v) for k,v in pool_inputs.items()}\n",
    "        \n",
    "    def map_and_screen(self, molecule: Molecule) -> list[Molecule]:\n",
    "        smile = molecule.smile\n",
    "        if smile.count('*') != len(self.mapping_idxs):\n",
    "            return []\n",
    "        \n",
    "        mapped_smiles = deduplicate_list(generate_mapping_permutations(smile, self.mapping_idxs, exact=True))\n",
    "        molecules = [Molecule(i) for i in mapped_smiles]\n",
    "        molecules = [i for i in molecules if self.template_screen(i)]\n",
    "        return molecules\n",
    "    \n",
    "    def template_screen(self, molecule: Molecule) -> bool:\n",
    "        if match_mapping(molecule, self.mapping_idxs):\n",
    "            return super().template_screen(molecule)\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def assembly_iterator(self, \n",
    "                          child_pools: list[FragmentNode], \n",
    "                          chunksize:   int) -> list[Tuple[Molecule]]:\n",
    "        g = product(*[i.items for i in child_pools])\n",
    "        for first in g:\n",
    "            yield list(chain([first], islice(g, chunksize - 1)))\n",
    "    \n",
    "    def _fuse(self, fusion_inputs: Tuple[Molecule]) -> Molecule:\n",
    "        fusion_string = '.'.join([i.smile for i in fusion_inputs])\n",
    "        fused_smile = fuse_smile_on_atom_mapping(fusion_string)\n",
    "        fusion_data = {\n",
    "            'source' : self.name,\n",
    "            'parents' : fusion_inputs,\n",
    "            'input_smiles' : fusion_string\n",
    "        }\n",
    "        molecule = Molecule(fused_smile, data=fusion_data)\n",
    "        return molecule\n",
    "    \n",
    "    def assemble(self, assembly_inputs: AssemblyInputs, verbose:bool=False) -> AssemblyPool:\n",
    "        child_pools = [child.assemble(assembly_inputs, verbose=verbose) for child in self.children]\n",
    "        \n",
    "        if verbose:\n",
    "            print(self.name)\n",
    "            \n",
    "        outputs = []\n",
    "        assembly_iterator = self.assembly_iterator(child_pools, assembly_inputs.assembly_chunksize)\n",
    "        \n",
    "        for fusion_inputs in assembly_iterator:\n",
    "            fused_pool = self.fuse(fusion_inputs, assembly_inputs.worker_pool)\n",
    "            fused_pool = fused_pool.filter(self.template_screen, worker_pool=assembly_inputs.worker_pool)\n",
    "            outputs += fused_pool.items\n",
    "            \n",
    "            if len(outputs) > assembly_inputs.max_assemblies_per_node:\n",
    "                break\n",
    "                \n",
    "        fused_pool = AssemblyPool(outputs)\n",
    "        \n",
    "        if assembly_inputs.log:\n",
    "            assembly_inputs.assembly_log[self.name] = {'inputs' : child_pools, 'outputs' : fused_pool}\n",
    "            \n",
    "        return fused_pool\n",
    "    \n",
    "    def repr_swap(self, input_str: str) -> str:\n",
    "        input_str = input_str.replace(f'Zr:{self.id}', self.name)\n",
    "        if hasattr(self, 'children'):\n",
    "            for child in self.children:\n",
    "                input_str = child.repr_swap(input_str)\n",
    "                \n",
    "        return input_str\n",
    "        \n",
    "    def __repr__(self) -> str:\n",
    "        rep_str = f'{self.name}: {self.repr_swap(self.dummy_smile)}'\n",
    "        if hasattr(self, 'children'):\n",
    "            rep_str += '\\n'\n",
    "            for child in self.children:\n",
    "                rep_str += '\\n\\t' + '\\n\\t'.join(child.__repr__().split('\\n'))\n",
    "                \n",
    "        return rep_str\n",
    "    \n",
    "    def dump(self):\n",
    "        dump_dict = {\n",
    "                    'name' : self.name,\n",
    "                    'node_type' : 'fragment_node',\n",
    "                    'template' : self.template,\n",
    "                    'children' : [i.dump() for i in self.children]\n",
    "                }\n",
    "        return dump_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class FragmentLeafNode(FragmentNode):\n",
    "    def __init__(self, \n",
    "                 name: str, \n",
    "                 mapping_idxs: list[int], \n",
    "                 template: Optional[Template]=None):\n",
    "        self.mapping_idxs = sorted(mapping_idxs)\n",
    "        super().__init__(name, [], template)\n",
    "        \n",
    "    def build_dummy(self):\n",
    "        self.dummy = get_dummy_mol(self.name, self.mapping_idxs, id=self.id)\n",
    "        self.dummy_smile = to_smile(self.dummy)\n",
    "        \n",
    "    def assemble(self, assembly_inputs: AssemblyInputs, verbose:bool=False) -> AssemblyPool:\n",
    "        if verbose:\n",
    "            print(self.name)\n",
    "        pool = assembly_inputs.pool_dict[self.name]\n",
    "        pool = pool.filter(self.template_screen, worker_pool=assembly_inputs.worker_pool)\n",
    "        return pool\n",
    "    \n",
    "    def dump(self):\n",
    "        dump_dict = {\n",
    "                        'name' : self.name,\n",
    "                        'node_type' : 'fragment_leaf_node',\n",
    "                        'mapping_idxs' : self.mapping_idxs,\n",
    "                        'template' : self.template\n",
    "                    }\n",
    "        return dump_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"F\",\n",
      " \"node_type\": \"fragment_node\",\n",
      " \"template\": null,\n",
      " \"children\": [\n",
      "  {\n",
      "   \"name\": \"R1\",\n",
      "   \"node_type\": \"fragment_leaf_node\",\n",
      "   \"mapping_idxs\": [\n",
      "    1\n",
      "   ],\n",
      "   \"template\": null\n",
      "  },\n",
      "  {\n",
      "   \"name\": \"R2\",\n",
      "   \"node_type\": \"fragment_leaf_node\",\n",
      "   \"mapping_idxs\": [\n",
      "    1\n",
      "   ],\n",
      "   \"template\": null\n",
      "  }\n",
      " ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "f1 = ['[*:1]C', '[*:1]N', '[*:2]O']\n",
    "f2 = ['[*:1]CC', '[*:1]CCC']\n",
    "\n",
    "m1 = [Molecule(i) for i in f1]\n",
    "m2 = [Molecule(i) for i in f2]\n",
    "\n",
    "p1 = AssemblyPool(m1)\n",
    "p2 = AssemblyPool(m2)\n",
    "\n",
    "assembly_dict = {\n",
    "    'R1' : p1,\n",
    "    'R2' : p2\n",
    "}\n",
    "\n",
    "assembly_inputs = AssemblyInputs(assembly_dict, 10000, 1e8)\n",
    "\n",
    "r1 = FragmentLeafNode('R1', [1])\n",
    "r2 = FragmentLeafNode('R2', [1])\n",
    "full = FragmentNode('F', [r1, r2])\n",
    "\n",
    "out = full.assemble(assembly_inputs)\n",
    "\n",
    "assert len(out)==4\n",
    "print(json.dumps(full.dump(), indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SynthonPool(AssemblyPool):\n",
    "    def __init__(self, items: list[Synthon]):\n",
    "        super().__init__(items)\n",
    "        self.mark_to_synthon = defaultdict(list)\n",
    "        \n",
    "        for synthon in self.items:\n",
    "            for mark in synthon.marks:\n",
    "                self.mark_to_synthon[mark].append(synthon)\n",
    "        \n",
    "    def get_matching(self, query_synthon: Synthon) -> list[Synthon]:\n",
    "        matching_synthons = []\n",
    "        for mark in query_synthon.compatible_marks:\n",
    "            matching_synthons += self.mark_to_synthon[mark]\n",
    "        return deduplicate_list(matching_synthons)\n",
    "    \n",
    "    def filter(self, filter_func: Callable, worker_pool: Optional[Pool]=None) -> SynthonPool:\n",
    "        if worker_pool:\n",
    "            bools = worker_pool.map(filter_func, self.items)\n",
    "            \n",
    "        else:\n",
    "            bools = [filter_func(i) for i in self.items]\n",
    "            \n",
    "        return SynthonPool([self.items[i] for i in range(len(self.items)) if bools[i]])\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'SynthonPool: {len(self.items)} items'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def make_pairs(pool1: SynthonPool, \n",
    "               pool2: SynthonPool):\n",
    "    for s1 in pool1.items:\n",
    "        matching = pool2.get_matching(s1)\n",
    "        for s2 in matching:\n",
    "            yield (s1, s2)\n",
    "\n",
    "def make_pairs_chunked(pool1: SynthonPool, \n",
    "                       pool2: SynthonPool, \n",
    "                       chunksize: int):\n",
    "    g = make_pairs(pool1, pool2)\n",
    "    for first in g:\n",
    "        yield list(chain([first], islice(g, chunksize-1)))\n",
    "\n",
    "def add_rxn(pair: Tuple[Synthon, Synthon], \n",
    "            rxn_universe: ReactionUniverse):\n",
    "    s1, s2 = pair\n",
    "    return (s1, s2, rxn_universe.get_matching_reactions(s1, s2))\n",
    "\n",
    "def make_assemblies(pool1: SynthonPool, \n",
    "                    pool2: SynthonPool, \n",
    "                    rxn_universe: ReactionUniverse, \n",
    "                    chunksize: int, \n",
    "                    worker_pool: Optional[Pool]=None):\n",
    "    \n",
    "    pair_gen = make_pairs_chunked(pool1, pool2, chunksize)\n",
    "    func = partial(add_rxn, rxn_universe=rxn_universe)\n",
    "    \n",
    "    output_assemblies = []\n",
    "    for chunk in pair_gen:\n",
    "        \n",
    "        if worker_pool:\n",
    "            chunk = worker_pool.map(func, chunk)\n",
    "        else:\n",
    "            chunk = [func(i) for i in chunk]\n",
    "\n",
    "        for assembly in chunk:\n",
    "            \n",
    "            if assembly[-1]:\n",
    "                output_assemblies.append(assembly)\n",
    "                \n",
    "            if len(output_assemblies)>= chunksize:\n",
    "                yield output_assemblies\n",
    "                output_assemblies = []\n",
    "    \n",
    "    \n",
    "    yield output_assemblies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SynthonNode(Node):\n",
    "    def __init__(self, \n",
    "                 name: str, \n",
    "                 incoming_node: SynthonNode, \n",
    "                 next_node: SynthonNode, \n",
    "                 rxn_universe: ReactionUniverse, \n",
    "                 n_func: set[int], \n",
    "                 template: Optional[Template]=None):\n",
    "        super().__init__(name, template)\n",
    "        self.incoming_node = incoming_node\n",
    "        self.next_node = next_node\n",
    "        self.rxn_universe = rxn_universe\n",
    "        self.n_func = n_func\n",
    "        self.grab_leaf_nodes()\n",
    "        \n",
    "    def grab_leaf_nodes(self):\n",
    "        self.leaf_nodes = []\n",
    "        stack = [self]\n",
    "        while stack:\n",
    "            current = stack.pop()\n",
    "            if isinstance(current, SynthonLeafNode):\n",
    "                self.leaf_nodes.append(current)\n",
    "            else:\n",
    "                stack.append(current.next_node)\n",
    "                stack.append(current.incoming_node)\n",
    "                \n",
    "    def map_molecule_to_leaf_nodes(self, synthon: Synthon) -> dict[str, list[Synthon]]:\n",
    "        output = {}\n",
    "        for node in self.leaf_nodes:\n",
    "            if node.template_screen(synthon):\n",
    "                output[node.name] = [synthon]\n",
    "            else:\n",
    "                output[node.name] = []\n",
    "        return output\n",
    "    \n",
    "    def build_assembly_pools(self, \n",
    "                             synthons: list[Synthon], \n",
    "                             worker_pool: Optional[Pool]=None\n",
    "                            ) -> dict[str, SynthonPool]:\n",
    "        if worker_pool:\n",
    "            mappings = worker_pool.map(self.map_molecule_to_leaf_nodes, synthons)\n",
    "        else:\n",
    "            mappings = [self.map_molecule_to_leaf_nodes(i) for i in synthons]\n",
    "            \n",
    "        pool_inputs = defaultdict(list)\n",
    "        for mapping in mappings:\n",
    "            for k,v in mapping.items():\n",
    "                pool_inputs[k] += v\n",
    "                \n",
    "        return {k:SynthonPool(v) for k,v in pool_inputs.items()}\n",
    "        \n",
    "    def template_screen(self, synthon: Synthon) -> bool:\n",
    "        n_func = synthon.recon_smile.count(':')\n",
    "        if (n_func in self.n_func) or (not self.n_func):\n",
    "            return super().template_screen(synthon)\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def reaction_screen(self, synthon: Synthon) -> bool:\n",
    "        if self.rxn_universe:\n",
    "            return bool(self.rxn_universe.get_matching_reactions(synthon))\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def _fuse(self, fusion_inputs: Tuple[Synthon, Synthon, list[FusionReaction]]) -> list[Synthon]:\n",
    "        s1, s2, valid_rxns = fusion_inputs\n",
    "        products = flatten_list([rxn.react(s1, s2) for rxn in valid_rxns])\n",
    "        \n",
    "        unique_products = defaultdict(list)\n",
    "        for product in products:\n",
    "            unique_products[product.smile].append(product)\n",
    "            \n",
    "        outputs = []\n",
    "        for k,v in unique_products.items():\n",
    "            product = v[0]\n",
    "            if len(v)>1:\n",
    "                product.data['reaction_tags'] = flatten_list([i.data['reaction_tags'] for i in v])\n",
    "            outputs.append(product)\n",
    "        return outputs\n",
    "    \n",
    "    def fuse(self, \n",
    "             fusion_inputs: Tuple[Synthon, Synthon, list[FusionReaction]], \n",
    "             worker_pool: Optional[Pool]=None) -> SynthonPool:\n",
    "        if worker_pool:\n",
    "            outputs = worker_pool.map(self._fuse, fusion_inputs)\n",
    "        else:\n",
    "            outputs = [self._fuse(i) for i in fusion_inputs]\n",
    "        return SynthonPool(flatten_list(outputs))\n",
    "    \n",
    "    def assemble(self, assembly_inputs: AssemblyInputs, verbose:bool=False) -> SynthonPool:\n",
    "        incoming_pool = self.incoming_node.assemble(assembly_inputs, verbose=verbose)\n",
    "        incoming_pool = incoming_pool.filter(self.reaction_screen, assembly_inputs.worker_pool)\n",
    "        \n",
    "        next_pool = self.next_node.assemble(assembly_inputs, verbose=verbose)\n",
    "        next_pool = next_pool.filter(self.reaction_screen, assembly_inputs.worker_pool)\n",
    "        \n",
    "        if verbose:\n",
    "            print(self.name)\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        assembly_generator = make_assemblies(incoming_pool, next_pool, self.rxn_universe,\n",
    "                                            assembly_inputs.assembly_chunksize, assembly_inputs.worker_pool)\n",
    "        \n",
    "        for assemblies in assembly_generator:\n",
    "            fused_pool = self.fuse(assemblies, assembly_inputs.worker_pool)\n",
    "            fused_pool = fused_pool.filter(self.template_screen, worker_pool=assembly_inputs.worker_pool)\n",
    "            outputs += fused_pool.items\n",
    "            \n",
    "            if len(outputs) > assembly_inputs.max_assemblies_per_node:\n",
    "                break\n",
    "                \n",
    "        fused_pool = SynthonPool(outputs)\n",
    "        \n",
    "        if assembly_inputs.log:\n",
    "            assembly_inputs.assembly_log[self.name] = {'inputs' : [incoming_pool, next_pool], \n",
    "                                                       'outputs' : fused_pool}\n",
    "            \n",
    "        return fused_pool\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'Synthon Product: {self.name}'\n",
    "    \n",
    "    def dump(self):\n",
    "        dump_dict = {\n",
    "                        'name' : self.name,\n",
    "                        'node_type' : 'synthon_node',\n",
    "                        'n_func' : self.n_func,\n",
    "                        'template' : self.template,\n",
    "                        'rxn_universe' : self.rxn_universe,\n",
    "                        'incoming_node' : self.incoming_node.dump(),\n",
    "                        'next_node' : self.next_node.dump()\n",
    "                    }\n",
    "        \n",
    "        return dump_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SynthonLeafNode(SynthonNode):\n",
    "    def __init__(self, \n",
    "                 name: str, \n",
    "                 n_func: set[int], \n",
    "                 template: Optional[Template]=None):\n",
    "        super().__init__(name, None, None, None, n_func, template)\n",
    "        \n",
    "    def assemble(self, assembly_inputs: AssemblyInputs, verbose:bool=False) -> SynthonPool:\n",
    "        if verbose:\n",
    "            print(self.name)\n",
    "        pool = assembly_inputs.pool_dict[self.name]\n",
    "        pool = pool.filter(self.template_screen, worker_pool=assembly_inputs.worker_pool)\n",
    "        return pool\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'Synthon Leaf: {self.name}'\n",
    "    \n",
    "    def dump(self):\n",
    "        dump_dict = {\n",
    "                        'name' : self.name,\n",
    "                        'node_type' : 'synthon_leaf_node',\n",
    "                        'n_func' : self.n_func,\n",
    "                        'template' : self.template,\n",
    "                    }\n",
    "        \n",
    "        return dump_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb1\n",
      "bb2\n",
      "product\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'product',\n",
       " 'node_type': 'synthon_node',\n",
       " 'n_func': {0},\n",
       " 'template': None,\n",
       " 'rxn_universe': <chem_templates.building_blocks.ReactionUniverse>,\n",
       " 'incoming_node': {'name': 'bb1',\n",
       "  'node_type': 'synthon_leaf_node',\n",
       "  'n_func': {1},\n",
       "  'template': None},\n",
       " 'next_node': {'name': 'bb2',\n",
       "  'node_type': 'synthon_leaf_node',\n",
       "  'n_func': {1},\n",
       "  'template': None}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = SynthonPool([Synthon('O=C(O)CCN[CH:10]=O'), Synthon('O=C(O)CCCN[CH:10]=O')])\n",
    "p2 = SynthonPool([Synthon('CCOC(=O)c1c([NH2:20])sc2c1CCNC2'), Synthon('C1CN(C2CC[NH:20]C2)CCN1')])\n",
    "rxn_universe = ReactionUniverse('all_rxns', REACTION_GROUPS)\n",
    "\n",
    "bb1 = SynthonLeafNode('bb1', set([1]))\n",
    "bb2 = SynthonLeafNode('bb2', set([1]))\n",
    "prod = SynthonNode('product', bb1, bb2, rxn_universe, set([0]))\n",
    "\n",
    "input_dict = {\n",
    "    'bb1' : p1,\n",
    "    'bb2' : p2\n",
    "}\n",
    "\n",
    "inputs = AssemblyInputs(input_dict, 10000, 10000)\n",
    "\n",
    "outputs = prod.assemble(inputs, verbose=True)\n",
    "assert len(outputs) == 4\n",
    "\n",
    "prod.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def build_synthesis_scheme(synthon: Synthon) -> dict:\n",
    "    output = {}\n",
    "    \n",
    "    if 'parents' in synthon.data:\n",
    "        if isinstance(synthon.data['parents'][0], Synthon):\n",
    "            output['result'] = synthon.smile\n",
    "            output['is_input'] = False\n",
    "            output['assembly_data'] = {'parents':[]}\n",
    "            output['assembly_data']['reaction_tags'] = synthon.data['reaction_tags']\n",
    "            \n",
    "            for i, parent in enumerate(synthon.data['parents']):\n",
    "                parent_data = build_synthesis_scheme(parent)\n",
    "                output['assembly_data']['parents'].append(parent_data)\n",
    "                            \n",
    "        else:\n",
    "            parent = synthon.data['parents'][0]\n",
    "            output['input'] = parent.smile\n",
    "            output['is_input'] = True\n",
    "            output['data'] = parent.data\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \"CCOC(=O)c1c(C)c(C(=O)C(C)Oc2cc(N)c(Br)cc2Br)n(C(=O)C2(Cc3ccc(Br)cc3F)CCCNC2)c1C\",\n",
      "  \"is_input\": false,\n",
      "  \"assembly_data\": {\n",
      "    \"parents\": [\n",
      "      {\n",
      "        \"result\": \"CCOC(=O)c1c(C)c(C(=O)C(C)Oc2cc(N)c(Br)cc2Br)[nH:20]c1C\",\n",
      "        \"is_input\": false,\n",
      "        \"assembly_data\": {\n",
      "          \"parents\": [\n",
      "            {\n",
      "              \"input\": \"Nc1cc(O)c(Br)cc1Br\",\n",
      "              \"is_input\": true,\n",
      "              \"data\": {\n",
      "                \"ID\": \"EN300-104251\"\n",
      "              }\n",
      "            },\n",
      "            {\n",
      "              \"input\": \"CCOC(=O)c1c(C)[nH]c(C(=O)C(C)Cl)c1C\",\n",
      "              \"is_input\": true,\n",
      "              \"data\": {\n",
      "                \"ID\": \"EN300-08472\"\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"reaction_tags\": [\n",
      "            \"O-SN alkylation\"\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"input\": \"O=C(O)C1(Cc2ccc(Br)cc2F)CCCNC1\",\n",
      "        \"is_input\": true,\n",
      "        \"data\": {\n",
      "          \"ID\": \"EN300-6745292\"\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"reaction_tags\": [\n",
      "      \"nH-Cu-mediated C-N coupling\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "bb1 = SynthonLeafNode('bb1', set([1]))\n",
    "bb2 = SynthonLeafNode('bb2', set([2]))\n",
    "prod1 = SynthonNode('product1', bb1, bb2, rxn_universe, set([1]))\n",
    "bb3 = SynthonLeafNode('bb3', set([1]))\n",
    "prod2 = SynthonNode('product2', prod1, bb3, rxn_universe, set([0]))\n",
    "\n",
    "mol1 = Molecule('Nc1cc(O)c(Br)cc1Br', {'ID' : 'EN300-104251'})\n",
    "mol2 = Molecule('CCOC(=O)c1c(C)[nH]c(C(=O)C(C)Cl)c1C', {'ID' : 'EN300-08472'})\n",
    "mol3 = Molecule('O=C(O)C1(Cc2ccc(Br)cc2F)CCCNC1', {'ID' : 'EN300-6745292'})\n",
    "\n",
    "p1 = SynthonPool(molecule_to_synthon(mol1))\n",
    "p2 = SynthonPool(molecule_to_synthon(mol2))\n",
    "p3 = SynthonPool(molecule_to_synthon(mol3))\n",
    "\n",
    "input_dict = {\n",
    "    'bb1' : p1,\n",
    "    'bb2' : p2,\n",
    "    'bb3' : p3\n",
    "}\n",
    "\n",
    "inputs = AssemblyInputs(input_dict, 10000, 10000)\n",
    "\n",
    "outputs = prod2.assemble(inputs, verbose=False)\n",
    "\n",
    "print(json.dumps(build_synthesis_scheme(outputs[0]), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def build_fragment_assembly_scheme(molecule: Molecule) -> dict:\n",
    "    output = {}\n",
    "    if 'parents' in molecule.data:\n",
    "        output['result'] = molecule.smile\n",
    "        output['is_input'] = False\n",
    "        output['assembly_data'] = {'parents':[]}\n",
    "        output['assembly_data']['input_smiles'] = molecule.data['input_smiles']\n",
    "        \n",
    "        for i, parent in enumerate(molecule.data['parents']):\n",
    "            parent_data = build_fragment_assembly_scheme(parent)\n",
    "            output['assembly_data']['parents'].append(parent_data)\n",
    "            \n",
    "    else:\n",
    "        output['input'] = molecule.smile\n",
    "        output['is_input'] = True\n",
    "        output['data'] = molecule.data\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \"CCC\",\n",
      "  \"is_input\": false,\n",
      "  \"assembly_data\": {\n",
      "    \"parents\": [\n",
      "      {\n",
      "        \"input\": \"C[*:1]\",\n",
      "        \"is_input\": true,\n",
      "        \"data\": {\n",
      "          \"test1\": \"test1\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"input\": \"CC[*:1]\",\n",
      "        \"is_input\": true,\n",
      "        \"data\": {\n",
      "          \"test2\": \"test2\"\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"input_smiles\": \"C[*:1].CC[*:1]\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "f1 = ['[*:1]C', '[*:1]N', '[*:2]O']\n",
    "f2 = ['[*:1]CC', '[*:1]CCC']\n",
    "\n",
    "m1 = [Molecule(i, data={'test1':'test1'}) for i in f1]\n",
    "m2 = [Molecule(i, data={'test2':'test2'}) for i in f2]\n",
    "\n",
    "p1 = AssemblyPool(m1)\n",
    "p2 = AssemblyPool(m2)\n",
    "\n",
    "assembly_dict = {\n",
    "    'R1' : p1,\n",
    "    'R2' : p2\n",
    "}\n",
    "\n",
    "assembly_inputs = AssemblyInputs(assembly_dict, 10000, 1e8)\n",
    "\n",
    "r1 = FragmentLeafNode('R1', [1])\n",
    "r2 = FragmentLeafNode('R2', [1])\n",
    "full = FragmentNode('F', [r1, r2])\n",
    "\n",
    "outputs = full.assemble(assembly_inputs)\n",
    "\n",
    "print(json.dumps(build_fragment_assembly_scheme(outputs[0]), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def build_assembly_from_dict(assembly_schema: dict) -> Node:\n",
    "\n",
    "    node_type = assembly_schema['node_type']\n",
    "    node_name = assembly_schema['name']\n",
    "    node_template = assembly_schema['template']\n",
    "    \n",
    "    if node_type=='fragment_leaf_node':\n",
    "        mapping_idxs = assembly_schema['mapping_idxs']\n",
    "        node = FragmentLeafNode(node_name, mapping_idxs, node_template)\n",
    "        \n",
    "    elif node_type=='fragment_node':\n",
    "        node_children = [build_assembly_from_dict(i) for i in assembly_schema['children']]\n",
    "        node = FragmentNode(node_name, node_children, node_template)\n",
    "\n",
    "    elif node_type=='synthon_leaf_node':\n",
    "        n_func = assembly_schema['n_func']\n",
    "        node = SynthonLeafNode(node_name, n_func, node_template)\n",
    "        \n",
    "    elif node_type=='synthon_node':\n",
    "        incoming_node = build_assembly_from_dict(assembly_schema['incoming_node'])\n",
    "        next_node = build_assembly_from_dict(assembly_schema['next_node'])\n",
    "        rxn_universe = assembly_schema['rxn_universe']\n",
    "        n_func = assembly_schema['n_func']\n",
    "        node = SynthonNode(node_name, incoming_node, next_node, rxn_universe, n_func, node_template)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f'node type {node_type} not found')\n",
    "        \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = {\n",
    " \"name\": \"F\",\n",
    " \"node_type\": \"fragment_node\",\n",
    " \"template\": None,\n",
    " \"children\": [\n",
    "  {\n",
    "   \"name\": \"R1\",\n",
    "   \"node_type\": \"fragment_leaf_node\",\n",
    "   \"mapping_idxs\": [1],\n",
    "   \"template\": None\n",
    "  },\n",
    "  {\n",
    "   \"name\": \"R2\",\n",
    "   \"node_type\": \"fragment_leaf_node\",\n",
    "   \"mapping_idxs\": [1],\n",
    "   \"template\": None\n",
    "  }\n",
    " ]\n",
    "}\n",
    "\n",
    "assembly_schema = build_assembly_from_dict(schema1)\n",
    "\n",
    "schema2 = {'name': 'product',\n",
    " 'node_type': 'synthon_node',\n",
    " 'n_func': {0},\n",
    " 'template': None,\n",
    " 'rxn_universe': ReactionUniverse('all_rxns', REACTION_GROUPS),\n",
    " 'incoming_node': {'name': 'bb1',\n",
    "  'node_type': 'synthon_leaf_node',\n",
    "  'n_func': {1},\n",
    "  'template': None},\n",
    " 'next_node': {'name': 'bb2',\n",
    "  'node_type': 'synthon_leaf_node',\n",
    "  'n_func': {1},\n",
    "  'template': None}}\n",
    "\n",
    "assembly_schema = build_assembly_from_dict(schema2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem_templates",
   "language": "python",
   "name": "chem_templates"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
